{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAR Fairness Audit: LLM Analysis\n\n**DS 112 Final Project**\n\nThis notebook uses Google Gemini to analyze VAR incident descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n!pip install pandas numpy matplotlib seaborn plotly scikit-learn scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set plotting style\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Google Gemini API\n\nFirst, let's set up the Google Gemini API for analyzing VAR incident descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the Google Generative AI library\n!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\nimport google.generativeai as genai\nimport time\n\n# Configure Gemini API (you'll need to provide your API key)\ntry:\n    from google.colab import userdata\n    api_key = userdata.get('GEMINI_API_KEY')\n    genai.configure(api_key=api_key)\n    print(\"API configured successfully!\")\nexcept:\n    print(\"To use Google Gemini API, add your API key to Colab secrets.\")\n    print(\"1. Get an API key from https://ai.google.dev/\")\n    print(\"2. Go to Runtime > Manage Secrets and add GEMINI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n\nLet's load the VAR dataset and prepare the incident descriptions for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the combined dataset\ndf = pd.read_csv('var_combined.csv')\n\n# Display the first few incident descriptions\nprint(\"Sample VAR Incident Descriptions:\")\ndf[['Description', 'IncidentType']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Incident Descriptions\n\nLet's use Google Gemini to analyze VAR incident descriptions for potential bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to analyze an incident description\ndef analyze_incident(incident_text, decision_type):\n    # Configure the model\n    model = genai.GenerativeModel('gemini-pro')\n    \n    # Create the prompt\n    prompt = f\"\"\"Analyze this soccer/football VAR (Video Assistant Referee) incident description objectively:\n    \n    Incident: {incident_text}\n    Official Decision: {decision_type}\n    \n    Based solely on this description, please evaluate:\n    1. Was this decision justified based on the rules of soccer?\n    2. Rate the controversy level of this decision (1-10 scale)\n    3. Is there any potential for bias in this decision?\n    \n    Provide your analysis in a structured format with clear reasoning.\"\"\"\n    \n    # Generate response\n    response = model.generate_content(prompt)\n    return response.text\n\n# Analyze a sample incident\nsample_idx = 0  # Change this to analyze different incidents\nsample_incident = df.iloc[sample_idx]\nprint(f\"Analyzing incident: {sample_incident['Description']}\")\nprint(f\"Decision: {sample_incident['IncidentType']}\\n\")\n\n# Call the analysis function\ntry:\n    analysis = analyze_incident(sample_incident['Description'], sample_incident['IncidentType'])\n    print(\"Gemini Analysis:\")\n    print(analysis)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Make sure you've added your API key to Colab secrets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Analysis\n\nLet's analyze multiple incidents and compile the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to analyze multiple incidents\ndef batch_analyze(incidents_df, n_samples=5):\n    # Sample incidents to analyze\n    if len(incidents_df) > n_samples:\n        samples = incidents_df.sample(n_samples, random_state=42)\n    else:\n        samples = incidents_df\n    \n    # Collect results\n    results = []\n    \n    # Analyze each sample\n    for i, incident in samples.iterrows():\n        try:\n            print(f\"Analyzing incident {i+1}/{len(samples)}...\")\n            analysis = analyze_incident(incident['Description'], incident['IncidentType'])\n            \n            # Add to results\n            results.append({\n                'IncidentID': i,\n                'description': incident['Description'],\n                'Decision': incident['IncidentType'],\n                'analysis': analysis\n            })\n            \n            # Sleep to avoid rate limiting\n            time.sleep(1)\n            \n        except Exception as e:\n            print(f\"Error analyzing incident {i}: {e}\")\n    \n    # Convert to DataFrame\n    return pd.DataFrame(results)\n\n# Uncomment to run batch analysis\n# Set n_samples to a small number for testing\n# analysis_results = batch_analyze(df, n_samples=3)\n# analysis_results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}